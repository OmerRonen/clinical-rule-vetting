# Shuffled the index
shuffle = sample(n,n)
from.what = c(rep(0, n-sum(z)), rep(1, sum(z)))[shuffle]
x = x[shuffle]
# Now computing EM-algorithm with
# theta_0 = (mean of first n/2, mean of last n/2, (n%/%2)/n)
emres1 = em(x, c(mean(x[1:n/2]), mean(x[(n/2+1):n]), 1/2))
clustered = as.numeric(emres1$w < 0.5)
table(from.what, clustered)
n = 1000
mu0 = 2
mu1 = 4
pi = 1/3
set.seed(1)
z = runif(n) > pi     # 0 for prob. \pi
x = c(rpois(n-sum(z), lambda = mu0), rpois(sum(z), lambda = mu1))
# Shuffled the index
shuffle = sample(n,n)
from.what = c(rep(0, n-sum(z)), rep(1, sum(z)))[shuffle]
x = x[shuffle]
# Now computing EM-algorithm with
# theta_0 = (mean of first n/2, mean of last n/2, (n%/%2)/n)
emres1 = em(x, c(mean(x[1:n/2]), mean(x[(n/2+1):n]), 1/2))
clustered = as.numeric(emres1$w < 0.5)
table(from.what, clustered)
rm(list = ls())
# set default knitr chunks
knitr::opts_chunk$set(
echo = TRUE,  # don't print the code chunk
warning = FALSE,  # don't print warnings
message = FALSE,  # don't print messages
fig.align = "center",  # always align figure in center # always plot figure at the exact location of the code chunk
cache = FALSE)  # don't cache results
# E-step
# Preparing for M-step, calculating W_{i,j}^(t)
# INPUT   : xi          single input
#           theta       (\mu_0, \mu_1, \pi)
# OUTPUT  : log (W_{i,0}^(t))
# NOTE W_{i,1}^(t) = 1 - W_{i,0}^(t)
poisf = function(xi, theta) {
mu0 = theta[1]
mu1 = theta[2]
pi  = theta[3]
part0 = xi * log(mu0) - mu0 + log(pi)
part1 = xi * log(mu1) - mu1 + log(1-pi)
return ( part0 - log(exp(part0) + exp(part1)) )
}
# INPUT   : x       length n, observed from poission mixture (\pi by Pois(\mu_0), 1-\pi by Pois(\mu_1))
#           theta   (\mu_0, \mu_1, \pi)
# OUTPUT  : w       length-n vector with W_{i,0}^(t)
estep = function(x, theta) {
w = sapply(x, function(y) poisf(y, theta))
return(exp(w))
}
# M-step
# Update theta
# INPUT   : x       length-n observed data
#         : w       W_{i,j}^(t) from E-step
# OUTPUT  : theta   Updated theta
mstep = function(x, w) {
theta = rep(0, 3)
theta[1] = sum(x * w) / sum(w)
theta[2] = sum(x * (1-w)) / sum(1-w)
theta[3] = sum(w) / length(x)
return(theta)
}
# EM-algorithm
# Computes E-step and M-step alternatively
# INPUT   : x           observed data
#           theta_0     initial theta
#           tol         when to stop
# OUTPUT  : W           final W_{i,0}^(t)
#           theta       final theta
em = function(x, theta_0, tol = 1e-5) {
theta.prev = theta_0
while(T) {
w = estep(x, theta.prev)
theta = mstep(x, w)
if (max(abs(theta-theta.prev)) < tol) break
theta.prev = theta
}
return(list(w = w, theta = theta))
}
n = 1000
mu0 = 2
mu1 = 4
pi = 1/3
set.seed(1)
z1 = runif(n) > pi     # 0 for prob. \pi
x1 = c(rpois(n-sum(z1), lambda = mu0), rpois(sum(z1), lambda = mu1))
# Shuffled the index
shuffle1 = sample(n,n)
from.what1 = c(rep(0, n-sum(z1)), rep(1, sum(z1)))[shuffle1]
x1 = x1[shuffle1]
# Now computing EM-algorithm with
# theta_0 = (mean of first n/2, mean of last n/2, (n%/%2)/n)
emres1 = em(x1, c(mean(x1[1:n/2]), mean(x1[(n/2+1):n]), 1/2))
clustered1 = as.numeric(emres1$w < 0.5)
table(from.what1, clustered1)
n = 1000
mu0 = 2
mu1 = 12
pi = 1/2
set.seed(1)
z2 = runif(n) > pi     # 0 for prob. \pi
x2 = c(rpois(n-sum(z2), lambda = mu0), rpois(sum(z2), lambda = mu1))
# Shuffled the index
shuffle2 = sample(n,n)
from.what2 = c(rep(0, n-sum(z2)), rep(1, sum(z2)))[shuffle2]
x2 = x2[shuffle2]
# Now computing EM-algorithm with
# theta_0 = (mean of first n/2, mean of last n/2, (n%/%2)/n)
emres2 = em(x2, c(mean(x2[1:n/2]), mean(x2[(n/2+1):n]), 1/2))
clustered2 = as.numeric(emres2$w < 0.5)
table(from.what2, clustered2)
emres1$theta
n = 1000
mu0 = 2
mu1 = 4
pi = 1/3
set.seed(1)
z1 = runif(n) > pi     # 0 for prob. \pi
x1 = c(rpois(n-sum(z1), lambda = mu0), rpois(sum(z1), lambda = mu1))
# Shuffled the index
shuffle1 = sample(n,n)
from.what1 = c(rep(0, n-sum(z1)), rep(1, sum(z1)))[shuffle1]
x1 = x1[shuffle1]
# Now computing EM-algorithm with
# theta_0 = (sort(mean of first n/2, mean of last n/2), (n%/%2)/n)
emres1 = em(x1, c(sort(mean(x1[1:n/2]), mean(x1[(n/2+1):n])), 1/2))
sort(mean(x1[1:n/2]), mean(x1[(n/2+1):n]))
emres1 = em(x1, c(sort(c(mean(x1[1:n/2]), mean(x1[(n/2+1):n]))), 1/2))
n = 1000
mu0 = 2
mu1 = 4
pi = 1/3
set.seed(1)
z1 = runif(n) > pi     # 0 for prob. \pi
x1 = c(rpois(n-sum(z1), lambda = mu0), rpois(sum(z1), lambda = mu1))
# Shuffled the index
shuffle1 = sample(n,n)
from.what1 = c(rep(0, n-sum(z1)), rep(1, sum(z1)))[shuffle1]
x1 = x1[shuffle1]
# Now computing EM-algorithm with
# theta_0 = (sort(mean of first n/2, mean of last n/2), (n%/%2)/n)
emres1 = em(x1, c(sort(c(mean(x1[1:n/2]), mean(x1[(n/2+1):n]))), 1/2))
clustered1 = as.numeric(emres1$w < 0.5)
table(from.what1, clustered1)
n = 1000
mu0 = 2
mu1 = 12
pi = 1/2
set.seed(1)
z2 = runif(n) > pi     # 0 for prob. \pi
x2 = c(rpois(n-sum(z2), lambda = mu0), rpois(sum(z2), lambda = mu1))
# Shuffled the index
shuffle2 = sample(n,n)
from.what2 = c(rep(0, n-sum(z2)), rep(1, sum(z2)))[shuffle2]
x2 = x2[shuffle2]
# Now computing EM-algorithm with
# theta_0 = (mean of first n/2, mean of last n/2, (n%/%2)/n)
emres2 = em(x2, c(sort(c(mean(x2[1:n/2]), mean(x2[(n/2+1):n]))), 1/2))
clustered2 = as.numeric(emres2$w < 0.5)
table(from.what2, clustered2)
n = 1000
mu0 = 2
mu1 = 3
pi = 1/10
set.seed(1)
z2 = runif(n) > pi     # 0 for prob. \pi
x2 = c(rpois(n-sum(z2), lambda = mu0), rpois(sum(z2), lambda = mu1))
# Shuffled the index
shuffle2 = sample(n,n)
from.what2 = c(rep(0, n-sum(z2)), rep(1, sum(z2)))[shuffle2]
x2 = x2[shuffle2]
# Now computing EM-algorithm with
# theta_0 = (mean of first n/2, mean of last n/2, (n%/%2)/n)
emres2 = em(x2, c(sort(c(mean(x2[1:n/2]), mean(x2[(n/2+1):n]))), 1/2))
clustered2 = as.numeric(emres2$w < 0.5)
table(from.what2, clustered2)
n = 1000
mu0 = 2
mu1 = 3
pi = 1/10
set.seed(1)
z3 = runif(n) > pi     # 0 for prob. \pi
x3 = c(rpois(n-sum(z3), lambda = mu0), rpois(sum(z3), lambda = mu1))
# Shuffled the index
shuffle3 = sample(n,n)
from.what3 = c(rep(0, n-sum(z3)), rep(1, sum(z3)))[shuffle3]
x3 = x3[shuffle3]
# Now computing EM-algorithm with
# theta_0 = (mean of first n/2, mean of last n/2, (n%/%2)/n)
emres3 = em(x3, c(sort(c(mean(x3[1:n/2]), mean(x3[(n/2+1):n]))), 1/2))
clustered3 = as.numeric(emres3$w < 0.5)
table(from.what3, clustered3)
?rbinom
n = 1000
pi0 = 0.2
pi1 = 0.8
pi = 1/2
set.seed(1)
z5 = runif(n) > pi     # 0 for prob. \pi
x5 = c(rbinom(n-sum(z5), 100, pi0), rbinom(sum(z5), 100, pi1))
# Shuffled the index
shuffle5 = sample(n,n)
from.what5 = c(rep(0, n-sum(z5)), rep(1, sum(z5)))[shuffle5]
x5 = x5[shuffle5]
# Now computing EM-algorithm with
# theta_0 = (mean of first n/2, mean of last n/2, (n%/%2)/n)
emres5 = em(x5, c(sort(c(mean(x5[1:n/2]), mean(x5[(n/2+1):n]))), 1/2))
clustered5 = as.numeric(emres5$w < 0.5)
table(from.what5, clustered5)
n = 1000
pi0 = 0.4
pi1 = 0.5
pi = 1/10
set.seed(1)
z6 = runif(n) > pi     # 0 for prob. \pi
x6 = c(rbinom(n-sum(z6), 100, pi0), rbinom(sum(z6), 100, pi1))
# Shuffled the index
shuffle6 = sample(n,n)
from.what6 = c(rep(0, n-sum(z6)), rep(1, sum(z6)))[shuffle6]
x6 = x6[shuffle6]
# Now computing EM-algorithm with
# theta_0 = (mean of first n/2, mean of last n/2, (n%/%2)/n)
emres6 = em(x6, c(sort(c(mean(x6[1:n/2]), mean(x6[(n/2+1):n]))), 1/2))
clustered6 = as.numeric(emres6$w < 0.5)
table(from.what6, clustered6)
n = 1000
pi0 = 0.3
pi1 = 0.7
pi = 1/2
set.seed(1)
z5 = runif(n) > pi     # 0 for prob. \pi
x5 = c(rbinom(n-sum(z5), 100, pi0), rbinom(sum(z5), 100, pi1))
# Shuffled the index
shuffle5 = sample(n,n)
from.what5 = c(rep(0, n-sum(z5)), rep(1, sum(z5)))[shuffle5]
x5 = x5[shuffle5]
# Now computing EM-algorithm with
# theta_0 = (mean of first n/2, mean of last n/2, (n%/%2)/n)
emres5 = em(x5, c(sort(c(mean(x5[1:n/2]), mean(x5[(n/2+1):n]))), 1/2))
clustered5 = as.numeric(emres5$w < 0.5)
table(from.what5, clustered5)
n = 1000
pi0 = 0.3
pi1 = 0.4
pi = 1/2
set.seed(1)
z5 = runif(n) > pi     # 0 for prob. \pi
x5 = c(rbinom(n-sum(z5), 100, pi0), rbinom(sum(z5), 100, pi1))
# Shuffled the index
shuffle5 = sample(n,n)
from.what5 = c(rep(0, n-sum(z5)), rep(1, sum(z5)))[shuffle5]
x5 = x5[shuffle5]
# Now computing EM-algorithm with
# theta_0 = (mean of first n/2, mean of last n/2, (n%/%2)/n)
emres5 = em(x5, c(sort(c(mean(x5[1:n/2]), mean(x5[(n/2+1):n]))), 1/2))
clustered5 = as.numeric(emres5$w < 0.5)
table(from.what5, clustered5)
n = 1000
pi0 = 0.4
pi1 = 0.6
pi = 1/3
set.seed(1)
z4 = runif(n) > pi     # 0 for prob. \pi
x4 = c(rbinom(n-sum(z4), 100, pi0), rbinom(sum(z4), 100, pi1))
# Shuffled the index
shuffle4 = sample(n,n)
from.what4 = c(rep(0, n-sum(z4)), rep(1, sum(z4)))[shuffle4]
x4 = x4[shuffle4]
# Now computing EM-algorithm with
# theta_0 = (mean of first n/2, mean of last n/2, (n%/%2)/n)
emres4 = em(x4, c(sort(c(mean(x4[1:n/2]), mean(x4[(n/2+1):n]))), 1/2))
clustered4 = as.numeric(emres4$w < 0.5)
table(from.what4, clustered4)
n = 1000
pi0 = 0.48
pi1 = 0.52
pi = 1/2
set.seed(1)
z5 = runif(n) > pi     # 0 for prob. \pi
x5 = c(rbinom(n-sum(z5), 100, pi0), rbinom(sum(z5), 100, pi1))
# Shuffled the index
shuffle5 = sample(n,n)
from.what5 = c(rep(0, n-sum(z5)), rep(1, sum(z5)))[shuffle5]
x5 = x5[shuffle5]
# Now computing EM-algorithm with
# theta_0 = (mean of first n/2, mean of last n/2, (n%/%2)/n)
emres5 = em(x5, c(sort(c(mean(x5[1:n/2]), mean(x5[(n/2+1):n]))), 1/2))
clustered5 = as.numeric(emres5$w < 0.5)
table(from.what5, clustered5)
n = 1000
pi0 = 0.4
pi1 = 0.6
pi = 1/10
set.seed(1)
z6 = runif(n) > pi     # 0 for prob. \pi
x6 = c(rbinom(n-sum(z6), 100, pi0), rbinom(sum(z6), 100, pi1))
# Shuffled the index
shuffle6 = sample(n,n)
from.what6 = c(rep(0, n-sum(z6)), rep(1, sum(z6)))[shuffle6]
x6 = x6[shuffle6]
# Now computing EM-algorithm with
# theta_0 = (mean of first n/2, mean of last n/2, (n%/%2)/n)
emres6 = em(x6, c(sort(c(mean(x6[1:n/2]), mean(x6[(n/2+1):n]))), 1/2))
clustered6 = as.numeric(emres6$w < 0.5)
table(from.what6, clustered6)
n = 1000
mu0 = 2
mu1 = 12
pi = 1/2
set.seed(1)
z2 = runif(n) > pi     # 0 for prob. \pi
x2 = c(rpois(n-sum(z2), lambda = mu0), rpois(sum(z2), lambda = mu1))
# Shuffled the index
shuffle2 = sample(n,n)
from.what2 = c(rep(0, n-sum(z2)), rep(1, sum(z2)))[shuffle2]
x2 = x2[shuffle2]
# Now computing EM-algorithm with
# theta_0 = (mean of first n/2, mean of last n/2, (n%/%2)/n)
emres2 = em(x2, c(sort(c(mean(x2[1:n/2]), mean(x2[(n/2+1):n]))), 1/2))
clustered2 = as.numeric(emres2$w < 0.5)
table(from.what2, clustered2)
n = 1000
mu0 = 1.8
mu1 = 2.2
pi = 1/2
set.seed(1)
z2 = runif(n) > pi     # 0 for prob. \pi
x2 = c(rpois(n-sum(z2), lambda = mu0), rpois(sum(z2), lambda = mu1))
# Shuffled the index
shuffle2 = sample(n,n)
from.what2 = c(rep(0, n-sum(z2)), rep(1, sum(z2)))[shuffle2]
x2 = x2[shuffle2]
# Now computing EM-algorithm with
# theta_0 = (mean of first n/2, mean of last n/2, (n%/%2)/n)
emres2 = em(x2, c(sort(c(mean(x2[1:n/2]), mean(x2[(n/2+1):n]))), 1/2))
clustered2 = as.numeric(emres2$w < 0.5)
table(from.what2, clustered2)
n = 1000
mu0 = 1.5
mu1 = 2.5
pi = 1/2
set.seed(1)
z2 = runif(n) > pi     # 0 for prob. \pi
x2 = c(rpois(n-sum(z2), lambda = mu0), rpois(sum(z2), lambda = mu1))
# Shuffled the index
shuffle2 = sample(n,n)
from.what2 = c(rep(0, n-sum(z2)), rep(1, sum(z2)))[shuffle2]
x2 = x2[shuffle2]
# Now computing EM-algorithm with
# theta_0 = (mean of first n/2, mean of last n/2, (n%/%2)/n)
emres2 = em(x2, c(sort(c(mean(x2[1:n/2]), mean(x2[(n/2+1):n]))), 1/2))
clustered2 = as.numeric(emres2$w < 0.5)
table(from.what2, clustered2)
n = 1000
pi0 = 0.45
pi1 = 0.55
pi = 1/2
set.seed(1)
z5 = runif(n) > pi     # 0 for prob. \pi
x5 = c(rbinom(n-sum(z5), 100, pi0), rbinom(sum(z5), 100, pi1))
# Shuffled the index
shuffle5 = sample(n,n)
from.what5 = c(rep(0, n-sum(z5)), rep(1, sum(z5)))[shuffle5]
x5 = x5[shuffle5]
# Now computing EM-algorithm with
# theta_0 = (mean of first n/2, mean of last n/2, (n%/%2)/n)
emres5 = em(x5, c(sort(c(mean(x5[1:n/2]), mean(x5[(n/2+1):n]))), 1/2))
clustered5 = as.numeric(emres5$w < 0.5)
table(from.what5, clustered5)
n = 1000
pi0 = 0.4
pi1 = 0.5
pi = 1/2
set.seed(1)
z5 = runif(n) > pi     # 0 for prob. \pi
x5 = c(rbinom(n-sum(z5), 100, pi0), rbinom(sum(z5), 100, pi1))
# Shuffled the index
shuffle5 = sample(n,n)
from.what5 = c(rep(0, n-sum(z5)), rep(1, sum(z5)))[shuffle5]
x5 = x5[shuffle5]
# Now computing EM-algorithm with
# theta_0 = (mean of first n/2, mean of last n/2, (n%/%2)/n)
emres5 = em(x5, c(sort(c(mean(x5[1:n/2]), mean(x5[(n/2+1):n]))), 1/2))
clustered5 = as.numeric(emres5$w < 0.5)
table(from.what5, clustered5)
478+192
n = 1000
pi0 = 0.3
pi1 = 0.6
pi = 1/3
set.seed(1)
z4 = runif(n) > pi     # 0 for prob. \pi
x4 = c(rbinom(n-sum(z4), 100, pi0), rbinom(sum(z4), 100, pi1))
# Shuffled the index
shuffle4 = sample(n,n)
from.what4 = c(rep(0, n-sum(z4)), rep(1, sum(z4)))[shuffle4]
x4 = x4[shuffle4]
# Now computing EM-algorithm with
# theta_0 = (mean of first n/2, mean of last n/2, (n%/%2)/n)
emres4 = em(x4, c(sort(c(mean(x4[1:n/2]), mean(x4[(n/2+1):n]))), 1/2))
clustered4 = as.numeric(emres4$w < 0.5)
table(from.what4, clustered4)
n = 1000
pi0 = 0.4
pi1 = 0.6
pi = 1/10
set.seed(1)
z6 = runif(n) > pi     # 0 for prob. \pi
x6 = c(rbinom(n-sum(z6), 100, pi0), rbinom(sum(z6), 100, pi1))
# Shuffled the index
shuffle6 = sample(n,n)
from.what6 = c(rep(0, n-sum(z6)), rep(1, sum(z6)))[shuffle6]
x6 = x6[shuffle6]
# Now computing EM-algorithm with
# theta_0 = (mean of first n/2, mean of last n/2, (n%/%2)/n)
emres6 = em(x6, c(sort(c(mean(x6[1:n/2]), mean(x6[(n/2+1):n]))), 1/2))
clustered6 = as.numeric(emres6$w < 0.5)
table(from.what6, clustered6)
780+95
n = 1000
mu0 = 2
mu1 = 3
pi = 1/10
set.seed(1)
z3 = runif(n) > pi     # 0 for prob. \pi
x3 = c(rpois(n-sum(z3), lambda = mu0), rpois(sum(z3), lambda = mu1))
# Shuffled the index
shuffle3 = sample(n,n)
from.what3 = c(rep(0, n-sum(z3)), rep(1, sum(z3)))[shuffle3]
x3 = x3[shuffle3]
# Now computing EM-algorithm with
# theta_0 = (mean of first n/2, mean of last n/2, (n%/%2)/n)
emres3 = em(x3, c(sort(c(mean(x3[1:n/2]), mean(x3[(n/2+1):n]))), 1/2))
clustered3 = as.numeric(emres3$w < 0.5)
table(from.what3, clustered3)
n = 1000
mu0 = 2
mu1 = 4
pi = 1/3
set.seed(1)
z1 = runif(n) > pi     # 0 for prob. \pi
x1 = c(rpois(n-sum(z1), lambda = mu0), rpois(sum(z1), lambda = mu1))
# Shuffled the index
shuffle1 = sample(n,n)
from.what1 = c(rep(0, n-sum(z1)), rep(1, sum(z1)))[shuffle1]
x1 = x1[shuffle1]
# Now computing EM-algorithm with
# theta_0 = (sort(mean of first n/2, mean of last n/2), (n%/%2)/n)
emres1 = em(x1, c(sort(c(mean(x1[1:n/2]), mean(x1[(n/2+1):n]))), 1/2))
clustered1 = as.numeric(emres1$w < 0.5)
table(from.what1, clustered1)
n = 1000
mu0 = 1.5
mu1 = 2.5
pi = 1/2
set.seed(1)
z2 = runif(n) > pi     # 0 for prob. \pi
x2 = c(rpois(n-sum(z2), lambda = mu0), rpois(sum(z2), lambda = mu1))
# Shuffled the index
shuffle2 = sample(n,n)
from.what2 = c(rep(0, n-sum(z2)), rep(1, sum(z2)))[shuffle2]
x2 = x2[shuffle2]
# Now computing EM-algorithm with
# theta_0 = (mean of first n/2, mean of last n/2, (n%/%2)/n)
emres2 = em(x2, c(sort(c(mean(x2[1:n/2]), mean(x2[(n/2+1):n]))), 1/2))
clustered2 = as.numeric(emres2$w < 0.5)
table(from.what2, clustered2)
n = 1000
pi0 = 0.4
pi1 = 0.6
pi = 1/10
set.seed(1)
z6 = runif(n) > pi     # 0 for prob. \pi
x6 = c(rbinom(n-sum(z6), 100, pi0), rbinom(sum(z6), 100, pi1))
# Shuffled the index
shuffle6 = sample(n,n)
from.what6 = c(rep(0, n-sum(z6)), rep(1, sum(z6)))[shuffle6]
x6 = x6[shuffle6]
# Now computing EM-algorithm with
# theta_0 = (mean of first n/2, mean of last n/2, (n%/%2)/n)
emres6 = em(x6, c(sort(c(mean(x6[1:n/2]), mean(x6[(n/2+1):n]))), 1/2))
clustered6 = as.numeric(emres6$w < 0.5)
table(from.what6, clustered6)
n = 1000
pi0 = 0.4
pi1 = 0.6
pi = 1/10
set.seed(1)
z6 = runif(n) > pi     # 0 for prob. \pi
x6 = c(rbinom(n-sum(z6), 100, pi0), rbinom(sum(z6), 100, pi1))
# Shuffled the index
shuffle6 = sample(n,n)
from.what6 = c(rep(0, n-sum(z6)), rep(1, sum(z6)))[shuffle6]
x6 = x6[shuffle6]
# Now computing EM-algorithm with
# theta_0 = (mean of first n/2, mean of last n/2, (n%/%2)/n)
emres6 = em(x6, c(sort(c(mean(x6[1:n/2]), mean(x6[(n/2+1):n]))), 1/2))
clustered6 = as.numeric(emres6$w < 0.5)
table(from.what6, clustered6)
?plot_ly
getwd()
rm(list = ls())
getwd()
setwd("../STAT215A/stat-215-a/rule-vetting/data/tbi_pecarn/raw")
data = read.csv("TBI PUD 10-08-2013.csv")
data[which(is.na(data$GCSTotal)), ]
data[is.na(data$GCSTotal)), 24:28]
data[is.na(data$GCSTotal), 24:28]
